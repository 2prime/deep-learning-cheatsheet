\documentclass[pdftex,10pt,a4paper]{scrartcl}

\usepackage[a4paper,left=2.5cm,right=2.5cm,bottom=3cm,top=3cm]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{url}
\usepackage{todonotes}
\usepackage[numbers,sort]{natbib}
\parindent=0cm

\title{Graph Convolutions}
\date{\vspace{-5ex}}

\begin{document}

\maketitle

\section{Preliminaries}

Let $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathbf{W})$ be a \emph{weighted graph} with $\mathcal{V} = \{1, \ldots, n\}$, $\mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}$ and \emph{adjacency matrix} $\mathbf{W} \in \mathbb{R}^{n \times n}$, where $W_{ij} > 0$ iff $(i, j) \in \mathcal{E}$ and $W_{ij} = 0$ iff $(i, j) \not\in \mathcal{E}$.
Note that $\mathbf{W}$ is usually \emph{sparse} with $|\mathcal{E}| \ll n^2$ entries.
$\mathcal{G}$ is called \emph{undirected} iff $W_{ij} = W_{ji}$ for all $i,j \in \mathcal{V}$.
We further assume that $\mathcal{G}$ contains no \emph{self-loops}, meaning $(i, i) \not\in \mathcal{E}$.
$\mathbf{W}$ implies the diagonal \emph{degree matrix} $\mathbf{D} \in \mathbb{R}^{n \times n}$, where $D_{ii} = \sum_{j \in \mathcal{V}} W_{ij}$.
For a node $i \in \mathcal{V}$ its \emph{neighborhood} set is defined by $\mathcal{N}(i)$.
% \\\\

% The \emph{unnormalized Laplacian} of an weighted undirected graph without self-loops is a $n \times n$ symmetric positive-semidefinite matrix $\mathbf{L} = \mathbf{D} - \mathbf{W}$, where $\mathbf{D} = \mathrm{diag}\left( \sum_{i \in \mathcal{V}} w_{ij}\right)$. (wrong syntax)
% The \emph{normalized Laplacian}

% $\mathcal{N}(i)$

% A \emph{signal} $f \colon \mathcal{V} \to \mathbb{R}^m$ respectively $\mathbf{F} \in \mathbb{R}^{n \times m}$
% Let $f \colon \mathcal{V} \to \mathbb{R}$ respectively $\mathbf{f} \in \mathbb{R}^n$ be a \emph{feature} on the nodes of the graph.


\section{Convolutions}

\paragraph{Spectral CNN}


Spectral networks and locally connected networks on graphs
Bruna et al 2014

\paragraph{Smooth Spectral CNN}

Deep convoltional networks on graph-structured data
Henaff 2015

\paragraph{ChebNet}

Defferrard

\paragraph{GCN}

Kipf

\paragraph{CayleyNet}

Graph Convoltional neural networks with complex reational spectral filters
Spectral CNN with complex rational filters
Levie et al 2017

\paragraph{Graph NN (GNN)}

First neural net on graphs with the name
A new model for learning in graph domains
Gori, Monfardini

\paragraph{Diffusion CNN (DCNN)}

Atwood 2016
Diffusion-convolutional neural networks

\paragraph{Geodesic CNN (GCNN)}

Geodesic convolution nueral networks on Riemannian manifolds
First spatial CNN on manifolds
Masci 2015

\paragraph{Anisotropic CNN (ACNN)}

Learning shape correspondence with anisotropic convoltional neural networks
Boscaini 2015

\paragraph{MoNet}

Let $\mathbf{u} \colon \mathcal{V} \times \mathcal{V} \to \mathbb{R}^d$ define a $d$-dimensional vector of \emph{pseudo-coordinates}.
\emph{MoNet}~\cite{Monti2016} then uses the generic \emph{patch operator}
\begin{equation*}
  D_k(i)f = \sum_{j \in \mathcal{N}(i)} w_k(\mathbf{u}(i, j)) f(j), \quad k \in \{ 1, \ldots, K \},
\end{equation*}
for the spatial definition of a convolution on a graph signal $f \colon \mathcal{V} \to \mathbb{R}$ respectively $\mathbf{f} \in \mathbb{R}^n$
\begin{equation*}
  (\mathbf{f} \star \mathbf{g})(i) = \sum_k^K D_k(i)f,
\end{equation*}
where $K \in \mathbb{N}$ is the dimensionality of the extracted patch and $\mathbf{w}(\mathbf{u}) = (w_1(\mathbf{u}), \ldots, w_K(\mathbf{u}))$ is a continuous kernel parametrized by some finite set of learnable parameters.
MoNet~\cite{Monti2016} suggests the use of the \emph{gaussian kernel}
\begin{equation*}
  w_k(\mathbf{u}) = \exp \left(-\frac{1}{2} {(\mathbf{u} - \boldsymbol{\mu}_k)}^{\top} {\mathrm{diag}(\boldsymbol{\sigma}_k)}^{-1} (\mathbf{u} - \boldsymbol{\mu}_k) \right)
\end{equation*}
with the diagonal covariance matrix $\mathrm{diag}(\boldsymbol{\sigma}_k) \in \mathbb{R}^{d \times d}$ and mean vector $\boldsymbol{\mu}_k \in \mathbb{R}^d$, resulting in $2Kd$ learnable parameters.
For arbitrary graphs one can choose the pseudo-coordinates to use the degrees of the nodes $\mathbf{u}(i,j) = \left( D_{ii}^{-1/2}, D_{jj}^{-1/2} \right)$, whereas one can take the polar coordinates $\mathbf{u} = (\rho, \varphi)$ respectively $\mathbf{u} = (r, \varphi, \theta)$ for 2D or 3d graph embeddings like discrete manifolds.

\paragraph{Localized SCNN}

Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks
Boscaini 2015

\paragraph{Spherical CNN}

Deep learing 3D shape surfaces using geometry images
CNN on spherical authalic parametrization
Sinha 2016

\paragraph{Toric CNN}

Convoltional neural networks on surfaces via seamless toric covers
CNN on planar flat-torus parametrization
Maron 2017

\paragraph{SyncSpecCNN}

Spectal transformer networks
CVPR
Yi 2017
SyncSpecCNN: Synchronized Spectral CNN for 3d Shape segmentation

\paragraph{SchNet}

NIPS 2017
Schuett
Modeling quantum interactions in molecules
no edges, only points

\paragraph{name?}

% Let $\xi = (t_0, \ldots, t_)$ be a node vector.
% An \emph{open b-spline-function} $N_k^m$ over $k \in \{ 1, \ldots, K \}$ is recursively defined by
% \begin{equation*}
%   N_k^0(t) = \begin{cases}
%     1 & \text{if } t \in [t_k, t_{k+1})\\
%     0 & \text{else}
%   \end{cases}
% \end{equation*}

% A \emph{closed b-spline-function}

% We choose a different weight function based on \emph{B-Splines} to make use of \emph{local controllable} filters and to reduce computation significantly~\cite{Fey2017}:
% \begin{equation*}
%   w_k(\rho, \varphi) = \mu_k \hat{\rho} \bar{N}_k^m(\varphi)
% \end{equation*}
% with $\boldsymbol{\mu} = (\mu_1, \ldots, \mu_K )$ learnable parameters where $\bar{N}_k^m$ is a closed b-spline-function of degree $m \in \mathbb{N}$ with uniform node vector over the interval $[0, 2\pi]$ and $\hat{\rho} = \exp(\frac{\rho^2}{2\sigma^2})$.
% \todo{emerging signal processing cite for gaussian}

% We can also use the Tensorproduktkonstruktion to also parametrize the distances via\todo{lol}
% \begin{equation*}
%   w_{kl}(\rho, \varphi) = \mu_{kl} N_k^m(\hat{\rho}) \bar{N}_l^m(\varphi)
% \end{equation*}
% where we combine open and closed b-spline functions.

% To modify it to the 3-dimenional space, one can use the polar coordinates $(\rho, \varphi, \theta)$ to
% \begin{equation*}
%   w_{klq}(\rho, \varphi, \theta) = \mu_{klm} N_k^m(\hat{\rho}) \bar{N}_l^m(\varphi) \bar{N}_q^m(\theta)
% \end{equation*}

% The good thing is the runtime.
% Whereas MoNet has a runtime dependent on $K$, which is typical the dominant factor between $d$ and $K$, this method is mostly dependent on $M$, which is typical low ($1$ or $2$).

% Computing $N_k^m(\cdot)$ for all edges and all $k \in \{ 1, \ldots, K \}$ yields $K$ adjacency matrices with $(m + 1) |\mathcal{E}|$ entries combined.

% If we further restrict $m = 1$, which leads to linear interpolation, we can reach a runtime nearly independent of $K$ with $\mathcal{O}(K |\mathcal{E}| + M^{\mathrm{in}} M^{\mathrm{out}} |\mathcal{E}|)$ which is quite as fast as the GCN introduced by Kipf et al.\todo{cite}

% \newpage

$n$ node count,
$d$ dimensionality,
$k$ partitions,
$m$ b-spline degree which should be fixed to $1$,
$y$ incoming features and
$z$ outgoing features.
\\
$\mathbf{W} \in \mathbb{R}^{k \times y \times z}$,
$\mathbf{F}^{\mathrm{in}} \in \mathbb{R}^{n \times y}$,
$\mathbf{A} \in \mathbb{R}^{n \times n \times d}$ and
$\mathbf{F}^{\mathrm{out}} \in \mathbb{R}^{n \times z}$.
\\
Let $N_i^m \colon [0, 1] \to [0, 1]$ be an open and $\bar{N}_i^m \colon [0, 2\pi] \to [0, 1]$ be a closed b-spline function with uniform node vectors.
We can redefine the kernel $\mathbf{w}(\mathbf{u})$ of the patch operator $D_k(i)f$ used in MoNet using localized b-spline functions as
\begin{equation*}
  w_i(\rho, \varphi) = \mu_i \hat{\rho} \bar{N}_i^m(\varphi)
\end{equation*}
respectively
\begin{equation*}
  w_{ij}(\rho, \varphi, \theta) = \mu_{ij} \hat{\rho} \bar{N}_i^m(\varphi) \bar{N}_j^m(\theta),
\end{equation*}
where the radius $\rho$ is inverted by the \emph{gaussian function} $\hat{\rho} = \exp(\frac{\rho^2}{2\sigma^2})$.
For an additional parametrization of $\rho$ one can also replace $\hat{\rho}$ with the corresponding b-spline functions resulting in
\begin{equation*}
  w_{ijk}(\rho, \varphi, \theta) = \mu_{ijk} N_i^m(\hat{\rho}) \bar{N}_j^m(\varphi) \bar{N}_k^m(\theta).
\end{equation*}
\\\\
Index-Notation nicht korrekt ($k$ wird hier als Index benutzt, $i$ und $j$ eigl reserviert fuer Knoten)
$\mu$ muss eigl ab zwei Indizes auch gross geschrieben werden
\\\\
% For every $N_i^m$
% First, do some element-wise preprocessing on $\mathbf{A}$ resulting in $2(m + 1)$ new $\mathbf{B} \in \mathbb{R}^{n \times n \times (m+1) \times 2}$ adjaceny matrices.








\newpage

\todo{normalize by node degree}
\todo{important: don't forget root nodes}
\todo{write tensor syntax down}

\begin{itemize}
  \item Insbesondere Gradienten beschreiben
\end{itemize}

\section{Applications}

\subsection{Images}

Classification task on MNIST~\cite{mnist} and Cifar-10~\cite{cifar10}.
MoNet uses superpixel-based approach with (fixed) 300, 150 and 75 vertices and no word on feature selection with 3 convolution layers and max pooling by a factor of four.
superpixel barycenters and 25! gaussian kernels initialized with random means and variances for 63! epochs
No word of runtime.
Each Superpixel is connected with each other (lol).

\subsection{Manifolds}

Learning dense intrinsic correspondence between collections of 3D shapes represented as discrete manifolds, where one tries to label each vertex of a given query shape $\mathcal{X}$ with the index of a corresponding point on some reference shape $\mathcal{Y}$.
Let $n$ and $m$ denote the number of vertices in $\mathcal{X}$ and $\mathcal{Y}$, respectively.
For a point $x$ on a query shape, the last layer of the network is a soft-max, producing an $m$-dimensional output $f(x)$ interpreted as a probability distribution on $\mathcal{Y}$.

\subsubsection{Shape correspondence}

\paragraph{Meshes}

FAUST humans dataset consisting of 100 watertight meshes representing $10$ different poses for $10$ different subjects with exact ground-truth correspondence.
Each shape is represented as a mesh with $6890$ vertices.
The first subject in first pose was used as the reference.
For all the shapes, point-wise 544-dimensional SHOT descriptors were used as input data.
MoNet architecture with 3 convolutional layers.
First 80 subjects in all poses were used for training (800 shapes in total), the remaining 20 subjects were used for testing.
The output of the network was refined using the intrinsic Bayesian filter in order to remove some local outliers.
Correspondnce quality was evaluated using the Princeton benchmark, plotting the percentage of matches that are at most $r$-geodesically distant from the groundtruth correspondence on the reference shape.

\paragraph{Range maps}

Repeated shape correspondence experiment on range maps synthetically generated from FASUT meshes.
For each subject and pose produced 10 rangemaps in $100 \times 180$ resolution, covering shape rotations around the $z$-axis with increments of $36$ degrees (total of $1000$ range maps).
For comparision, we show the performance of a stanrard Euclidean CNN applied on raw depth values and on SHOT descriptors.

\subsubsection{Shape retrieval}

In the shape retrieval application, we are interested in producing a global shape descriptor that discrimnates between shape classes.

\subsubsection{Invariant descriptors}

Point-wise applying some input feature vector, the output can be regarded as a dense local descriptor at point $x$.
Our goal is to make the output of the network as similar as possible at coresponding points (positives) across a collection of shapes, and as dissimilar as possible at non-corresponding points (negatives).
For this purpose, we use a siamese network configuration and minimize the siamese loss.

\paragraph{GCNN}

also used the TOSCA dataset containing syntetic models of humans in a variety of near-isometric deformations.
The meshes in TOSCA were resamples to $10$K vertices.

\section{Multi graphs}

was von monti 2017
CNNs on multiple graphs and application to matrix completion

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
